GENERAL:
  experiment: all_tooth
  seed: 0

DATA:
  # data path
  root_dir: D:/dataset/Teeth_box/data
  split_dir: D:/dataset/Teeth_box
  # batch_size per gpu
  batch_size: 1
  # sample
  num_points: 9998
  # augmentation
  augmentation: True
  normalize_pc: False

STRUCTURE:
  k: 16
  k_detr: 20
  input_channels: 15
  output_channels: 17
  query_num: 30  # 50
  n_decoder: 1
  n_edgeconvs_backbone: 5
  emb_dims: 1024
  global_pool_backbone: avg   # max or avg
  norm: instance
  use_stn: False # spatial transformer network
  dynamic: False
  dropout: 0.

TRAIN:
  max_epochs: 50
  weight_decay: 0.0001
  delta: 0.1667
  batch_size: 1
  load_from_checkpoint:
  resume_from_checkpoint:

  # one cycle lr scheduler
  lr_max: 0.001
  pct_start: 0.1    # percentage of the cycle spent increasing lr
  div_factor: 25    # determine the initial lr (lr_max / div_factor)
  final_div_factor: 1e4   # determine the final lr (lr_max / final_div_factor)
  start_epoch: 0

  train_file: train.txt
  train_workers: 2

  val_workers: 2
  val_file: val.txt

  test_workers: 2
  test_file: test.txt